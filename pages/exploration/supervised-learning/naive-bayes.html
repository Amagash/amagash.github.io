<!DOCTYPE html>
<html lang="en-us">

<head>
    <title>Naive Bayes</title>
    <!-- prettyprint -->
    <script src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js"></script>
    <!-- responsive -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb"
        crossorigin="anonymous">
    <!-- fontawesome -->
    <script src="https://use.fontawesome.com/1ebdada262.js"></script>
    <!-- code editor -->
    <link rel="stylesheet" href="../../../assets/css/code-theme-lakeside-custom.css">
    <!-- tooltip -->
    <link rel="stylesheet" href="../../../assets/css/tooltip.css">
    <!-- CSS -->
    <link rel="stylesheet" href="../../../assets/css/main.css">
    <!-- math formulas -->
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script>

</head>

<body>
    <div class="sidebar-nav-thin">
        <ul>
            <a href='../../../index.html'>
                <li class='d-flex justify-content-center align-items-center tooltip-right' data-tooltip='Home'>
                    <i class="fa fa-home fa-fw fa-2x" aria-hidden="true"></i>
                </li>
            </a>
            <a href=#intro>
                <li class='d-flex justify-content-center align-items-center tooltip-right' data-tooltip='Introduction'>
                    <i class="fa fa-angle-double-up fa-fw fa-2x" aria-hidden="true"></i>
                </li>
            </a>
            <a href=#car>
                <li class='d-flex justify-content-center align-items-center tooltip-right' data-tooltip='Self-driving car'>
                    <i class="fa fa-car fa-fw fa-2x" aria-hidden="true"></i>
                </li>
            </a>
            <a href=#enron>
                <li class='d-flex justify-content-center align-items-center tooltip-right' data-tooltip='Enron Corpus'>
                    <i class="fa fa-archive fa-fw fa-2x" aria-hidden="true"></i>
                </li>
            </a>
        </ul>
    </div>
    <div class="exp-background">
        <div class="exp-marge">
            <div class="exp-title">
                <h1>
                    Gaussian Naive Bayes
                </h1>
            </div>
            <div class='exp-content'>
                <section id='intro'>
                    <h2>
                        Introduction
                    </h2>
                    <div class='intro'>
                        Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption
                        of independence between every pair of features.
                    </div>
                    <br/>
                    <p>
                        <b>The advantages of Naive Bayes include :</b>
                    </p>
                    <ul>
                        <li>
                            They require a small amount of training data to estimate the necessary parameters.
                        </li>
                        <li>
                            Naive Bayes learners and classifiers can be extremely fast compared to more sophisticated methods.
                        </li>
                        <li>
                            The decoupling of the class conditional feature distributions means that each distribution can be independently estimated
                            as a one dimensional distribution. This in turn helps to alleviate problems stemming from the
                            curse of dimensionality.
                        </li>
                    </ul>
                    <p>
                        <b>The disadvantages of Naive Bayes include :</b>
                    </p>
                    <ul>
                        <li>
                            Although naive Bayes is known as a decent classifier, it is known to be a bad estimator, so the probability outputs from
                            predict_proba are not to be taken too seriously.
                        </li>
                    </ul>
                    <div class='row no-gutters d-flex align-items-center'>
                        <div class="col-md-6 col-sm-12">
                            <p>
                                Here is an example with a test cancer diagnostic (more on
                                <a href='https://goo.gl/syWgMi' target='_blank'>Udacity</a>) :
                            </p>
                            <ul>
                                <li>
                                    <b>P(C)</b> : The
                                    <b>prior</b> condition here is the probability of having cancer.
                                </li>
                                <li>
                                    <b>P(pos|C)</b> : The
                                    <b>sensitivity</b> is the probability of the test being positive given that the person has
                                    cancer.
                                </li>
                                <li>
                                    <b>P(neg|¬C)</b> : The
                                    <b>specificity</b> if the probability of the test being negative given that the person does
                                    not have cancer.
                                </li>
                            </ul>
                            <p>
                                $$P(C|pos) = {P(pos|C) P(C)\over P(pos)}$$
                            </p>

                            <p>
                                $$P(¬C|pos) = {P(pos|¬C) P(¬C)\over P(pos)}$$
                            </p>
                            <!-- <p>
                                $$P(x_i|y) = {1\over \sqrt{2 \pi \sigma^2_y }}( exp {-(x_i - \mu _y)^2 \over 2\sigma ^2_y}).$$
                            </p> -->
                        </div>
                        <div class="col-md-6 col-sm-12">
                            <a href='https://goo.gl/syWgMi' target='_blank'>
                                <img src="../../../assets/images/exploration/naive-bayes/nb-scheme.png">
                            </a>
                        </div>
                    </div>
                </section>
                <section id='car'>
                    <h2>
                        Gaussian Naive Bayes for self-driving car
                    </h2>
                    <div>
                        <div class='intro'>
                            <p>
                                We want to train a car to decide weither or not it can drive faster or if it should slow down depending on the terrain. Two
                                features will be taken into account in this project :
                            </p>
                            <ul class='in-paragraph'>
                                <li>
                                    Bumpiness: the more bumps on the road, the slower the car should go.
                                </li>
                                <li>
                                    Steepness: the steeper the road, the slower the car should go.
                                </li>
                            </ul>
                            <p>
                                I will describe the procedure I went through step by step using Gaussian Naive Bayes as classifiers.
                            </p>

                        </div>
                        </p>
                        <ol>
                            <li>
                                <p>
                                    We first need to create a dataset of terrain with the features bumpiness and steepness along with a label "fast" or "slow".
                                    From this labeled dataset, we will be able to build a decision tree to help the car make
                                    it's decision : "Should I go slow or fast?"
                                </p>

                                <pre class="prettyprint">
                                <code class="language-python">
### Modified from: Udacity - Intro to Machine Learning

import random
def makeTerrainData(n_points):
    random.seed(42)
    ### generate random data for both features 'grade' and 'bumpy' with an error
    grade = [random.random() for ii in range(0,n_points)]
    bumpy = [random.random() for ii in range(0,n_points)]
    error = [random.random() for ii in range(0,n_points)]

    ### data are labeled depending on their features and error.
    ### label "slow" if labels = 1.0 
    ### label "fast" if labels = 0.0
    labels = [round(grade[ii]*bumpy[ii]+0.3+0.1*error[ii]) for ii in range(0,n_points)]

    ### adjust labels for extreme cases (>0.8) of bumpiness or steepness
    for ii in range(0, len(y)):
        if grade[ii]>0.8 or bumpy[ii]>0.8:
            labels[ii] = 1.0

    ### split into train set (75% of data generated) and test sets (25% of data generated)
    features = [[gg, ss] for gg, ss in zip(grade, bumpy)]
    split = int(0.75*n_points)
    features_train = features[0:split]
    features_test  = features[split:]
    labels_train = labels[0:split]
    labels_test  = labels[split:]

    return features_train, labels_train, features_test, labels_test
                                </code>
                            </pre>
                                <p>
                                    The outputs are as follows for n_points = 10 :
                                </p>
                                <div class="responsive-wrapper">
                                    <table class="table table-bordered text-justify">
                                        <thead>
                                            <tr>
                                                <th colspan="2">features_train</th>
                                                <th>labels_train</th>
                                                <th colspan="2">features_test</th>
                                                <th>labels_test</th>
                                            </tr>
                                        </thead>
                                        <tbody>
                                            <tr>
                                                <td>grade</td>
                                                <td>bumpiness</td>
                                                <td>slow = 1.0 | fast = 0.0</td>
                                                <td>grade</td>
                                                <td>bumpiness</td>
                                                <td>slow = 1.0 | fast = 0.0</td>
                                            </tr>
                                            <tr>
                                                <td>0.64</td>
                                                <td>0.22</td>
                                                <td>1.0</td>
                                                <td>0.09</td>
                                                <td>0.59</td>
                                                <td>0.0</td>
                                            </tr>
                                            <tr>
                                                <td>0.03</td>
                                                <td>0.51</td>
                                                <td>0.0</td>
                                                <td>0.42</td>
                                                <td>0.81</td>
                                                <td>1.0</td>
                                            </tr>
                                            <tr>
                                                <td>0.28</td>
                                                <td>0.03</td>
                                                <td>0.0</td>
                                                <td>0.03</td>
                                                <td>0.01</td>
                                                <td>0.0</td>
                                            </tr>
                                            <tr>
                                                <td>0.22</td>
                                                <td>0.20</td>
                                                <td>0.0</td>
                                                <td></td>
                                                <td></td>
                                                <td></td>
                                            </tr>
                                            <tr>
                                                <td>0.74</td>
                                                <td>0.64</td>
                                                <td>1.0</td>
                                                <td></td>
                                                <td></td>
                                                <td></td>
                                            </tr>
                                            <tr>
                                                <td>0.68</td>
                                                <td>0.54</td>
                                                <td>1.0</td>
                                                <td></td>
                                                <td></td>
                                                <td></td>
                                            </tr>
                                            <tr>
                                                <td>0.89</td>
                                                <td>0.22</td>
                                                <td>1.0</td>
                                                <td></td>
                                                <td></td>
                                                <td></td>
                                            </tr>
                                        </tbody>
                                    </table>
                                </div>
                                <p>
                                    For n_points = 1000, we get the following repartition of test points. We consider the feature 'bumpiness' on the x-axis and
                                    'grade' on the y axis. Each feature in a gradient between 0 and 1. Each point previously
                                    generated has two coordinates bumpiness and grade. When we plot the test points (features_test)
                                    - representing 25% of our generated data - we can see the pattern separating the points
                                    labeled 'slow' and 'fast'.
                                </p>
                                <div class="images">
                                    <img src='../../../assets/images/exploration/naive-bayes/nb-testset.png' </li>
                                    <p class='fig-title'>Testing set plotted with their labels</p>
                                    <p class='fig-legend'>
                                        Testing set includes all features_test (grade, bumpiness) with their labels_test (slow or fast)
                                    </p>
                                </div>
                            </li>
                            <li>
                                <p>
                                    Now with our training set (features_train), we can train our classifier to predict a point's label depending on its features.
                                    We will use the
                                    <a href='https://goo.gl/7U5eU6' target="_blank">class sklearn.naive_bayes.GaussianNB()</a>.
                                </p>

                                <br/>
                                <pre class="prettyprint">
                                <code class="language-python">
from prep_terrain_data import makeTerrainData
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score

### generate the dataset for 1000 points (see previous code)
features_train, labels_train, features_test, labels_test = makeTerrainData(1000)

### create the classifier
clf = GaussianNB()

### fit the training set
clf.fit(features_train, labels_train)

### now let's make predictions on the test set
prediction = clf.predict(features_test)

### measure of the accuracy score by comparing the prediction with the actual labels of the testing set
accuracy = accuracy_score(labels_test, pred)
                                </code>
                            </pre>
                                <p>
                                    Here I plotted the points from the testing set (features_test) with their labels (labels_test). On top is the prediction
                                    made by the classifier after fitting on the training set.
                                </p>
                                <div class="images">
                                    <img src='../../../assets/images/exploration/naive-bayes/nb-car.png' </li>
                                    <p class='fig-title'>Decision tree with min_samples_split = 2</p>
                                    <p class='fig-legend'></p>
                                </div>
                                <p>
                                    <div class="responsive-wrapper">
                                        <table class="table">
                                            <thead class="thead-light">
                                                <tr>
                                                    <th scope="col">Classifier</th>
                                                    <th scope="col">Training time (sec)</th>
                                                    <th scope="col">Predict time (sec)</th>
                                                    <th scope="col">Accuracy</th>
                                                </tr>
                                            </thead>
                                            <tbody>
                                                <tr>
                                                    <th scope="row">Gaussian Naive Bayes</th>
                                                    <td>0.003</td>
                                                    <td>0.001</td>
                                                    <td>0.884</td>
                                                </tr>
                                            </tbody>
                                        </table>
                                    </div>
                                </p>
                            </li>
                        </ol>
                    </div>
                </section>
                <section id='enron'>
                    <h2>
                        Identifying emails authors with Gaussian Naive Bayes
                    </h2>
                    <div class='intro'>
                        <p>
                            Enron was one of the largest US companies in 2000. At the end of 2001, it had collapsed into bankruptcy due to widespread
                            corporate fraud, known since as the
                            <a href='https://en.wikipedia.org/wiki/Enron_scandal' target='_blank'>Enron scandal</a>. A vast amount of confidential information including thousands of emails and
                            financial data was made public after Federal investigation.
                        </p>
                        <p>
                            In this project, I will apply Gaussian Naive Bayes to identify authors of emails in the Enron Corpus.
                        </p>
                    </div>
                    <br/>
                    <ol>
                        <li>
                            <p>
                                A big first part of the project is the preprocessing of emails which is described in more details
                                <a href="../../exploration/supervised-learning/text-learning.html">here</a>.
                            </p>
                        </li>
                        <li>
                            <p>
                                Once the emails are preprocessed and separated into a training and a testing set, the
                                <a href='https://goo.gl/7U5eU6' target="_blank">class sklearn.naive_bayes.GaussianNB()</a>
                                can be used.
                            </p>
                            <pre class="prettyprint">
                                        <code class="language-python">
from sklearn.naive_bayes import GaussianNB

def nb_email(features_train, features_test, labels_train, labels_test):
    clf = GaussianNB()
    t0 = time()
    pred = clf.fit(features_train, labels_train)
    print ("naive bayes training time :", round(time() - t0, 3), "s")
    t0 = time()
    pred2 = clf.predict(features_test)
    print ("naive bayes predict time :", round(time() - t0, 3), "s")
    accuracy = accuracy_score(labels_test, pred2)
    print ("naive bayes accuracy :", accuracy)

def main():
    from_sara_file = "from_sara.txt"
    from_chris_file = "from_chris.txt"
    word_data, from_data = preprocess_email(from_sara_file, from_chris_file)
    features_train, features_test, labels_train, labels_test = vectorize(word_data, from_data)
    nb_email(features_train, features_test, labels_train, labels_test)

if __name__ == '__main__':
    main()
                                        </code>
                                    </pre>
                            <div class="responsive-wrapper">
                                <table class="table">
                                    <thead class="thead-light">
                                        <tr>
                                            <th>Classification algorithm</th>
                                            <th>Training time (sec)</th>
                                            <th>Predict time (sec)</th>
                                            <th>Accuracy</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <th>Gaussian Naive Bayes</th>
                                            <td>9.182</td>
                                            <td>1.905</td>
                                            <td>97.497</td>
                                        </tr>
                                    </tbody>
                                </table>
                            </div>
                        </li>
                    </ol>
                </section>
            </div>
        </div>
    </div>
</body>

</html>